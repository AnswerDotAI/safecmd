{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58dff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp bashxtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce08b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import shlex,subprocess,json,shutil\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbfc9f1",
   "metadata": {},
   "source": [
    "# Bashxtract API\n",
    "> Extract commands used from bash command lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654af97",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94eb28",
   "metadata": {},
   "source": [
    "`safecmd.bashxtract` provides tools for parsing and extracting commands from bash command strings. It's designed for security-conscious applications where you need to understand exactly what commands a shell script will execute before running it.\n",
    "\n",
    "The core use case is validating shell commands from untrusted sources (like LLM-generated commands) against an allowlist. Rather than trying to regex-match bash syntax—which is notoriously tricky—this module uses `shfmt`, a proper bash parser, to build an AST and then extracts all executable commands from it.\n",
    "\n",
    "It's likely that the only function you'll actually need from here is `extract_commands`. But we provide a full API of all the pieces we use to build that function, which we'll take you through here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89fb3ff",
   "metadata": {},
   "source": [
    "## The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae64bdac",
   "metadata": {},
   "source": [
    "Parsing bash commands is surprisingly tricky. You might think `shlex.split` would work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '''\n",
    "echo | head 2 <<EOF\n",
    "asdf\n",
    "jkljl\n",
    "EOF\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5c970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['echo', '|', 'head', '2', '<<EOF', 'asdf', 'jkljl', 'EOF']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shlex.split(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2741d",
   "metadata": {},
   "source": [
    "But `shlex` doesn't understand bash syntax—it treats `|`, `<<EOF`, and the heredoc content as regular arguments. It can't tell us that `echo` and `head` are separate commands in a pipeline, or that the heredoc content is input, not an argument.\n",
    "\n",
    "Fortunately, there's a proper bash parser called `shfmt` that can parse bash into a JSON AST (Abstract Syntax Tree). The `shfmt-py` package (installed automatically with safecmd) provides the binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd66f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: shfmt [flags] [path ...]\r\n",
      "\r\n",
      "shfmt formats shell programs. If the only argument is a dash ('-') or no\r\n",
      "arguments are given, standard input will be used. If a given path is a\r\n",
      "directory, all shell scripts found under that directory will be used.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!shfmt --help 2>&1 | head -6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437e7f07",
   "metadata": {},
   "source": [
    "…and this is the key flag that we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --to-json           print syntax tree to stdout as a typed JSON\r\n"
     ]
    }
   ],
   "source": [
    "!shfmt --help 2>&1 | grep to-json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3731d",
   "metadata": {},
   "source": [
    "As we'll see below, the AST that `shfmt` creates represents the structure of the bash command as nested dictionaries. Each node has a `Type` field telling us what kind of construct it is—`CallExpr` for a command invocation, `BinaryCmd` for pipelines and logical operators, `Word` for arguments, and so on. From this, we can pull out just the information we need.\n",
    "\n",
    "For our heredoc example, what we ultimately want is to extract:\n",
    "\n",
    "1. **The commands**: `['echo']` and `['head', '2']`\n",
    "2. **The operators used**: `{'|'}` (a pipe)\n",
    "3. **The heredoc content** attached to the command that receives it\n",
    "\n",
    "So our goal is to walk this AST and produce a simple list of commands with their arguments, plus a set of operators—something we can easily validate against an allowlist.\n",
    "\n",
    "The module is structured in layers:\n",
    "\n",
    "1. **Parsing layer** (`parse_bash`): Converts bash syntax to a JSON AST using shfmt\n",
    "2. **Text extraction** (`part_text`, `word_text`): Reconstructs text values from AST nodes, handling quotes, escapes, and expansions\n",
    "3. **AST walking** (`visit_stmts`, `nested_stmts`): Recursively traverses the AST to find all commands, including those nested in substitutions\n",
    "4. **Operator detection** (`collect_ops`): Identifies shell operators like pipes, redirects, and logical operators\n",
    "5. **Validation** (`check_types`): Ensures we only process bash constructs we understand\n",
    "6. **Main API** (`extract_commands`): Combines everything into a simple interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff67c4",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_bash(cmd:str, shfmt:str='shfmt'):\n",
    "    \"Parse `cmd` using `shfmt`\"\n",
    "    if not shutil.which(shfmt):\n",
    "        raise FileNotFoundError(f\"{shfmt} not found in PATH. If you installed safecmd with --user, add ~/.local/bin to your PATH.\")\n",
    "    res = subprocess.run([shfmt, '--to-json'], input=cmd, capture_output=True, text=True)\n",
    "    if res.returncode != 0: raise ValueError(res.stderr)\n",
    "    return json.loads(res.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3128924",
   "metadata": {},
   "source": [
    "Parses a bash command string using `shfmt --to-json` and returns the AST as a Python dict. Raises `ValueError` if the command has syntax errors. Requires the `shfmt` binary to be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e6ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Type': 'File',\n",
       " 'Pos': {'Offset': 0, 'Line': 1, 'Col': 1},\n",
       " 'End': {'Offset': 10, 'Line': 1, 'Col': 11},\n",
       " 'Stmts': [{'Pos': {'Offset': 0, 'Line': 1, 'Col': 1},\n",
       "   'End': {'Offset': 10, 'Line': 1, 'Col': 11},\n",
       "   'Cmd': {'Type': 'CallExpr',\n",
       "    'Pos': {'Offset': 0, 'Line': 1, 'Col': 1},\n",
       "    'End': {'Offset': 10, 'Line': 1, 'Col': 11},\n",
       "    'Args': [{'Pos': {'Offset': 0, 'Line': 1, 'Col': 1},\n",
       "      'End': {'Offset': 4, 'Line': 1, 'Col': 5},\n",
       "      'Parts': [{'Type': 'Lit',\n",
       "        'Pos': {'Offset': 0, 'Line': 1, 'Col': 1},\n",
       "        'End': {'Offset': 4, 'Line': 1, 'Col': 5},\n",
       "        'ValuePos': {'Offset': 0, 'Line': 1, 'Col': 1},\n",
       "        'ValueEnd': {'Offset': 4, 'Line': 1, 'Col': 5},\n",
       "        'Value': 'echo'}]},\n",
       "     {'Pos': {'Offset': 5, 'Line': 1, 'Col': 6},\n",
       "      'End': {'Offset': 10, 'Line': 1, 'Col': 11},\n",
       "      'Parts': [{'Type': 'Lit',\n",
       "        'Pos': {'Offset': 5, 'Line': 1, 'Col': 6},\n",
       "        'End': {'Offset': 10, 'Line': 1, 'Col': 11},\n",
       "        'ValuePos': {'Offset': 5, 'Line': 1, 'Col': 6},\n",
       "        'ValueEnd': {'Offset': 10, 'Line': 1, 'Col': 11},\n",
       "        'Value': 'hello'}]}]},\n",
       "   'Position': {'Offset': 0, 'Line': 1, 'Col': 1}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_bash('echo hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72685f24",
   "metadata": {},
   "source": [
    "## Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c322e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def part_text(p, cmd):\n",
    "    \"Extracts the text value from a single word part node in the shfmt AST.\"\n",
    "    t = p.get('Type', '')\n",
    "    if t == 'Lit': return p['Value'].replace('\\\\ ', ' ')\n",
    "    if t == 'SglQuoted': return p['Value']\n",
    "    if t in ('DblQuoted', 'Hdoc'): return ''.join(part_text(x, cmd) for x in p.get('Parts', []))\n",
    "    if t == 'ParamExp':\n",
    "        name = p['Param']['Value']\n",
    "        if p.get('Index'): name += '[' + word_text(p['Index'], cmd) + ']'\n",
    "        return '${' + name + '}' if p.get('Rbrace') else '$' + name\n",
    "    if t in ('CmdSubst', 'ProcSubst'):\n",
    "        start, end = p['Pos']['Offset'], p['End']['Offset']\n",
    "        return cmd[start:end]\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7058cbe",
   "metadata": {},
   "source": [
    "Handles literals (with backslash-space unescaping), single/double quoted strings, parameter expansions (`$var`, `${var}`, `${arr[0]}`), and command/process substitutions. For substitutions, returns the original source text using offset positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f8727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo bar'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_text({'Type': 'SglQuoted', 'Value': 'foo bar'}, \"echo 'foo bar'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def word_text(w, cmd):\n",
    "    \"Converts a Word node (with `Parts`) into its full text repr by concatenating `part_text` for each part.\"\n",
    "    return ''.join(part_text(p, cmd) for p in w.get('Parts', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3b586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_text({'Parts': [{'Type': 'Lit', 'Value': 'hello'}]}, 'echo hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nested_stmts(parts):\n",
    "    \"Yield all Stmts lists from nested Parts recursively\"\n",
    "    for p in parts:\n",
    "        if stmts := p.get('Stmts'): yield stmts\n",
    "        yield from nested_stmts(p.get('Parts', []))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d2a6e1",
   "metadata": {},
   "source": [
    "Generator that recursively yields all `Stmts` lists found within nested `Parts` arrays. Used to find command substitutions (`$(...)`) and process substitutions (`<(...)`) at any nesting depth, including those inside double-quoted strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf8cce4",
   "metadata": {},
   "source": [
    "## AST Walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84758156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Cmd': {Ellipsis}}]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts = [{'Type': 'CmdSubst', 'Stmts': [{'Cmd': {...}}]}]\n",
    "list(nested_stmts(parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def visit_stmts(stmts, cmd, commands=None):\n",
    "    \"Visit statements, appending commands and handling redirects\"\n",
    "    if commands is None: commands=[]\n",
    "    def visit(n):\n",
    "        if not n: return\n",
    "        if args := n.get('Args'):\n",
    "            commands.append([word_text(a, cmd) for a in args])\n",
    "            for a in args:\n",
    "                for s in nested_stmts(a.get('Parts', [])): visit_stmts(s, cmd, commands)\n",
    "        for k in ('Cmd', 'X', 'Y', 'Cond', 'Then', 'Else', 'Do', 'Loop'): visit(n.get(k))\n",
    "        for k in ('Stmts', 'Items', 'Cases'): visit_stmts(n.get(k), cmd, commands)\n",
    "    for s in stmts or []:\n",
    "        visit(s)\n",
    "        for r in s.get('Redirs', []):\n",
    "            if not commands: continue\n",
    "            if hdoc := r.get('Hdoc'): commands[-1].append(word_text(hdoc, cmd).rstrip('\\n'))\n",
    "            elif r.get('Op') == 63: commands[-1].extend(['<<<', word_text(r['Word'], cmd)])\n",
    "    return commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33051b",
   "metadata": {},
   "source": [
    "Walks a list of statement nodes from the shfmt AST, extracting all commands (including nested ones) into the `commands` list. Each command is represented as `[cmd, arg1, arg2, ...]`. Handles redirects by appending heredoc/here-string content to the most recent command. Returns the commands list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e9122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['echo', 'foo'], ['cat', 'file']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = parse_bash('echo foo; cat file')\n",
    "visit_stmts(parsed['Stmts'], 'echo foo; cat file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba597a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "_op_map = {10: '&&', 11: '||', 12: '|', 13: '|&', 54: '>', 55: '>>', 56: '<', 58: '<&', 59: '>&', 64: '&>', 65: '&>>'}\n",
    "_attr_ops = {'Background': '&', 'Semicolon': ';', 'Assigns': '='}\n",
    "\n",
    "def collect_ops(node, ops=None):\n",
    "    \"Walk AST node and collect all operators into a set\"\n",
    "    if ops is None: ops = set()\n",
    "    if not isinstance(node, dict): return ops\n",
    "    for attr, op in _attr_ops.items():\n",
    "        if node.get(attr): ops.add(op)\n",
    "    if op := _op_map.get(node.get('Op')): ops.add(op)\n",
    "    for v in node.values(): collect_ops(v, ops) if isinstance(v, dict) else [collect_ops(x, ops) for x in v] if isinstance(v, list) else None\n",
    "    return ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71faa5f3",
   "metadata": {},
   "source": [
    "Detects `&`, `;`, logical AND/OR (`&&`/`||`), pipe (`|`), and redirections (`>`, `>>`, `<`) by checking the `Op` field against `OP_MAP` and the `Background`/`Semicolon` boolean flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fec425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'&&', '>', '|'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_ops(parse_bash('echo a && echo b | cat > out.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e038c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "HANDLED_TYPES = {'File', 'CallExpr', 'BinaryCmd', 'Subshell', 'Block', 'IfClause', 'WhileClause', \n",
    "    'ForClause', 'CaseClause', 'CaseItem', 'FuncDecl', 'DeclClause', 'Lit', 'SglQuoted', 'DblQuoted',\n",
    "    'ParamExp', 'CmdSubst', 'ProcSubst', 'Hdoc', 'Word', 'Redirect', 'Comment', 'ArithmExp', 'ArithmCmd'}\n",
    "\n",
    "def check_types(node):\n",
    "    \"Raise ValueError if AST contains unhandled node types\"\n",
    "    if not isinstance(node, dict): return\n",
    "    if (t := node.get('Type')) and t not in HANDLED_TYPES: raise ValueError(f\"Unhandled bash construct: {t}\")\n",
    "    for v in node.values():\n",
    "        if isinstance(v, dict): check_types(v)\n",
    "        elif isinstance(v, list): [check_types(x) for x in v]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261b73f",
   "metadata": {},
   "source": [
    "Raises `ValueError` if any node has a `Type` not in `HANDLED_TYPES`. Use this to detect unsupported bash constructs early, ensuring the rest of the parsing pipeline won't silently skip or mishandle unknown syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_types(parse_bash('echo hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7452889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught unhandled construct\n"
     ]
    }
   ],
   "source": [
    "try: check_types(parse_bash('[[ -f foo ]]'))\n",
    "except ValueError: print('Caught unhandled construct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c570a",
   "metadata": {},
   "source": [
    "## Main API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_commands(cmd, shfmt='shfmt'):\n",
    "    \"Split bash command into (commands, operators)\"\n",
    "    ast = parse_bash(cmd, shfmt=shfmt)\n",
    "    check_types(ast)\n",
    "    return visit_stmts(ast.get('Stmts', []), cmd), collect_ops(ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f3f15",
   "metadata": {},
   "source": [
    "`extract_commands(cmd)` parses a bash command string and returns a list of all commands that would be executed, including those embedded in command substitutions, process substitutions, pipelines, and compound statements.\n",
    "\n",
    "Each command is represented as a list of tokens (strings), similar to the output of `shlex.split()`. The function uses `shfmt` to parse the bash syntax into an AST, then extracts all executable commands recursively.\n",
    "\n",
    "**Handled constructs:**\n",
    "- Simple commands: `echo foo` → `[['echo', 'foo']]`\n",
    "- Pipelines: `cat file | grep x` → `[['cat', 'file'], ['grep', 'x']]`\n",
    "- Sequences (`;`, `&`, `&&`, `||`): `echo a; echo b` → `[['echo', 'a'], ['echo', 'b']]`\n",
    "- Command substitution: `echo $(whoami)` → `[['echo', '$(whoami)'], ['whoami']]`\n",
    "- Backtick substitution: `` echo `whoami` `` → `[['echo', '`whoami`'], ['whoami']]`\n",
    "- Process substitution: `diff <(ls a) <(ls b)` → `[['diff', ...], ['ls', 'a'], ['ls', 'b']]`\n",
    "- Subshells: `(cd /tmp && rm *)` → `[['cd', '/tmp'], ['rm', '*']]`\n",
    "- Nested substitutions are extracted recursively\n",
    "- Heredocs (`<<EOF`) and here-strings (`<<<`) have their content inlined as a single token\n",
    "- Quoted strings and escaped spaces are handled correctly, preserving them as single tokens\n",
    "\n",
    "The return value is a 2-ple with the above list as the 1st element, and the result of `collect_ops` as the 2nd.\n",
    "\n",
    "The tests below show the full behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61964be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(a, *b, ops=set()): test_eq(extract_commands(a), (list(b), ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915025f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split('echo <<EOF\\nasdf\\njkljl\\nEOF\\n', ['echo', 'asdf\\njkljl'])\n",
    "test_split('echo $(foo)', ['echo', '$(foo)'], ['foo'])\n",
    "test_split('echo $(foo) | cat -a', ['echo', '$(foo)'], ['foo'], ['cat', '-a'], ops={'|'})\n",
    "test_split('echo $(cat $(ls))', ['echo', '$(cat $(ls))'], ['cat', '$(ls)'], ['ls'])\n",
    "test_split('echo \"hello world\" foo', ['echo', 'hello world', 'foo'])\n",
    "test_split('echo hello\\\\ world', ['echo', 'hello world'])\n",
    "test_split('echo foo; echo bar', ['echo', 'foo'], ['echo', 'bar'], ops={';'})\n",
    "test_split('echo $HOME \"${USER}\"', ['echo', '$HOME', '${USER}'])\n",
    "test_split('sleep 10 &', ['sleep', '10'], ops={';', '&'})\n",
    "test_split('cat <<< \"some text\"', ['cat', '<<<', 'some text'])\n",
    "test_split(\"echo \\\"it's a 'test'\\\"\", ['echo', \"it's a 'test'\"])\n",
    "test_split('echo \"hello $(whoami) there\"', ['echo', 'hello $(whoami) there'], ['whoami'])\n",
    "test_split('echo \"path is ${HOME}/bin\"', ['echo', 'path is ${HOME}/bin'])\n",
    "test_split('echo ${arr[0]}', ['echo', '${arr[0]}'])\n",
    "test_split('echo \"$(echo \"inner\")\"', ['echo', '$(echo \"inner\")'], ['echo', 'inner'])\n",
    "test_split('echo \"$HOME/$(whoami)/file\"', ['echo', '$HOME/$(whoami)/file'], ['whoami'])\n",
    "test_split('echo `whoami`', ['echo', '`whoami`'], ['whoami'])\n",
    "test_split('(cd /tmp && rm -rf *)', ['cd', '/tmp'], ['rm', '-rf', '*'], ops={'&&'})\n",
    "test_split('eval \"rm -rf /\"', ['eval', 'rm -rf /'])\n",
    "test_split('echo a && echo b || echo c', ['echo', 'a'], ['echo', 'b'], ['echo', 'c'], ops={'&&', '||'})\n",
    "test_split('cat file > out', ['cat', 'file'], ops={'>'})\n",
    "test_split('cat file >> out', ['cat', 'file'], ops={'>>'})\n",
    "test_split('cat < in', ['cat'], ops={'<'})\n",
    "test_split('diff <(ls dir1) <(ls dir2)',\n",
    "    ['diff', '<(ls dir1)', '<(ls dir2)'], ['ls', 'dir1'], ['ls', 'dir2'])\n",
    "test_split('FOO=bar', ops={'='})\n",
    "test_split('FOO=bar echo hello', ['echo', 'hello'], ops={'='})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eac266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split('echo &>file', ['echo'], ops={'&>'})\n",
    "test_split('echo &>>file', ['echo'], ops={'&>>'})\n",
    "test_split('echo |& cat', ['echo'], ['cat'], ops={'|&'})\n",
    "\n",
    "test_split('echo >&2', ['echo'], ops={'>&'})\n",
    "test_split('cat <&3', ['cat'], ops={'<&'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d0b20",
   "metadata": {},
   "source": [
    "## export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
